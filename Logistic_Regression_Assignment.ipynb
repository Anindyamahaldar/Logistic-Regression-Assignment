{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n"
      ],
      "metadata": {
        "id": "drtkR7nI8RtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Questions"
      ],
      "metadata": {
        "id": "9TO_ND7L8Wnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical"
      ],
      "metadata": {
        "id": "0G1BJ8Rw8bnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "   - Logistic regression predicts the probability of a categorical outcome (like yes/no, true/false), while linear regression predicts a continuous outcome (like price or weight).\n",
        "\n",
        "2. What is the mathematical equation of Logistic Regression?\n",
        "   - Logistic regression is a model in which the log odds are linear. This is equivalent to saying P(Y=1∣X=xi)=11+e−x⊺iθ. If you plug this into the expression for ℓ(θ), you obtain the log-likelihood for logistic regression.\n",
        "\n",
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "   - The answer says: \"Logistic regression models use the sigmoid function to estimate the probability of a binary event, such as dead vs.. alive, sick vs well, fraudulent vs.\n",
        "\n",
        "4. What is the cost function of Logistic Regression?\n",
        "   - The cost function used in Logistic Regression is Log Loss (also known as Binary Cross-Entropy Loss), which measures the difference between predicted probabilities and actual class labels, penalizing incorrect predictions more heavily as they deviate from the true labels.\n",
        "\n",
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "   - Regularization in logistic regression is a technique that prevents overfitting by adding a penalty term to the cost function, reducing model complexity and improving generalization on unseen data. It's needed when a model learns too much from the specific training data and fails to generalize well to new data.\n",
        "\n",
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression?\n",
        "   - Lasso regression uses L1 regularization, shrinking coefficients to zero for feature selection, while Ridge regression uses L2 regularization, shrinking coefficients towards zero but not to zero, and Elastic Net combines both, balancing feature selection and coefficient shrinkage.\n",
        "\n",
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "   - Elastic Net is useful when there are many correlated features, as it balances Ridge and Lasso to avoid Lasso's tendency to remove one feature randomly while keeping another. It provides a more stable and generalizable model compared to using Lasso or Ridge alone.\n",
        "\n",
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "   - In logistic regression, the regularization parameter (λ), or its inverse (C), controls the balance between model complexity and fit, preventing overfitting and improving generalization performance. A higher λ (or lower C) leads to stronger regularization, shrinking coefficients and creating a simpler model, while a lower λ (or higher C) results in weaker regularization, allowing the model to fit the data more closely.\n",
        "\n",
        "9. What are the key assumptions of Logistic Regression?\n",
        "   - The key assumptions of logistic regression include a binary or categorical dependent variable, independent observations, linearity of independent variables with the log-odds of the outcome, and the absence of multicollinearity among independent variables.\n",
        "\n",
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "    - For classification tasks, alternatives to logistic regression include decision trees, random forests, support vector machines (SVMs), and neural networks, each offering unique strengths and weaknesses.\n",
        "\n",
        "11. What are Classification Evaluation Metrics?\n",
        "    - Classification evaluation metrics are quantitative measures used to assess the performance of a machine learning model in classification tasks, providing insights into how well the model predicts class labels. Common metrics include accuracy, precision, recall, F1-score, and AUC-ROC.\n",
        "\n",
        "12. How does class imbalance affect Logistic Regression?\n",
        "    - Class imbalance in datasets can negatively impact logistic regression by causing the model to favor the majority class and perform poorly on the minority class, leading to biased predictions and reduced overall accuracy.\n",
        "\n",
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "    - Hyperparameter tuning involves selecting the optimal values of hyperparameters, which affect the performance of the Logistic Regression model. Some common hyperparameters that can be tuned include the learning rate, regularization strength, batch size, and number of iterations.\n",
        "\n",
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "    - In Logistic Regression, different solvers are essentially optimization algorithms used to find the best model parameters. The choice of solver depends on the size and characteristics of your dataset, particularly the number of samples, features, and whether you need L1 regularization. Here's a breakdown of some common solvers and when to use them:\n",
        "        - liblinear:\n",
        "This solver is efficient for small datasets and is particularly suitable when dealing with high dimensionality or sparse data. It supports L1 and L2 regularization but only works with one-versus-rest multiclass classification.\n",
        "        - sag (Stochastic Average Gradient):\n",
        "This solver is designed for large datasets. It uses stochastic gradient descent, which means it updates the parameters based on random subsets of the data, making it computationally efficient.\n",
        "        - newton-cg (Newton's Method with Conjugate Gradient):\n",
        "This solver is computationally intensive as it explicitly computes the Hessian matrix. However, it can be very fast for datasets where the number of samples is significantly larger than the number of features.\n",
        "\n",
        "\n",
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "    - When there are more than two classes in the target vector, the one-vs-one strategy allows logistic regression to train a separate model for each class against every individual remaining class. If the target vector has n number of classes, this strategy will create n * (n-1) / 2 models.\n",
        "\n",
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "    - Advantages: Linear regression is easy to implement, interpret, and works well with linear relationships. Disadvantages: It struggles with complex, nonlinear data, is sensitive to outliers, and assumes independence, homoscedasticity, and normality, which may not hold in many real-world scenarios.\n",
        "\n",
        "17. What are some use cases of Logistic Regression?\n",
        "     - Logistic regression, a machine learning algorithm for binary classification, finds use in predicting outcomes with two possibilities (like yes/no, true/false) across various fields, including healthcare, finance, marketing, and more.\n",
        "\n",
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "    - Softmax regression is a generalization of logistic regression used for multi-class classification, while logistic regression is primarily used for binary classification (two classes). Softmax regression uses the softmax function to output probabilities for each class, ensuring they sum to 1, whereas logistic regression uses the sigmoid function for binary classification.\n",
        "\n",
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "    - For multiclass classification, you choose between One-vs-Rest (OvR) and Softmax based on the type of model you're using and the desired output format: OvR is a strategy for training binary classifiers, while Softmax is an activation function that outputs probabilities for each class.\n",
        "\n",
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "    - In logistic regression, coefficients represent the change in the log-odds of the outcome for a one-unit change in the predictor variable, holding all other variables constant. Exponentiating the coefficient yields the odds ratio, showing the multiplicative change in odds.\n"
      ],
      "metadata": {
        "id": "Ay-7VDqG8g7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "nXAFaC3HAbL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "-hu4h1NZAc2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gep1AxiL7_7A",
        "outputId": "c38762bc-fbb7-41fd-a010-26fae2ccdeb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def logistic_regression_example():\n",
        "    \"\"\"\n",
        "    Loads a dataset, splits it, trains a Logistic Regression model,\n",
        "    and prints the model's accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset (you can replace this with your own)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_example()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "aOJORON7A2ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def lasso_logistic_regression_example():\n",
        "    \"\"\"\n",
        "    Loads a dataset, splits it, trains a Logistic Regression model with L1 regularization (Lasso),\n",
        "    and prints the model's accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset (you can replace this with your own)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model with L1 regularization (Lasso)\n",
        "    model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)  # Use liblinear for L1\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Lasso Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lasso_logistic_regression_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTZKrDjIA1uX",
        "outputId": "9f868c09-8d1d-400f-d7a6-2cc803d736e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Logistic Regression Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "UAjHSojPBICH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def ridge_logistic_regression_example():\n",
        "    \"\"\"\n",
        "    Loads a dataset, splits it, trains a Logistic Regression model with L2 regularization (Ridge),\n",
        "    prints the model's accuracy, and coefficients.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset (you can replace this with your own)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model with L2 regularization (Ridge)\n",
        "    model = LogisticRegression(penalty='l2', max_iter=1000) # lbfgs is the default solver for l2, and handles multi-class\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Ridge Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Print the model coefficients\n",
        "    print(\"\\nModel Coefficients:\")\n",
        "\n",
        "    # Handle multi-class coefficients correctly\n",
        "    if len(model.coef_.shape) > 1: #multi-class\n",
        "        for i, coef in enumerate(model.coef_):\n",
        "            print(f\"Class {i}: {coef}\")\n",
        "    else: #binary-class\n",
        "        print(model.coef_)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ridge_logistic_regression_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLkeyqH8BGL2",
        "outputId": "f44a21b9-4214-4c64-bf0a-b2ebbf9be290"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Logistic Regression Accuracy: 1.0000\n",
            "\n",
            "Model Coefficients:\n",
            "Class 0: [-0.39340204  0.96258576 -2.37510761 -0.99874603]\n",
            "Class 1: [ 0.50840364 -0.25486503 -0.21301366 -0.77575487]\n",
            "Class 2: [-0.1150016  -0.70772072  2.58812127  1.77450091]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "SdW56Y8aBY2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def elastic_net_logistic_regression_example(l1_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Loads a dataset, splits it, trains a Logistic Regression model with Elastic Net regularization,\n",
        "    and prints the model's accuracy and coefficients.\n",
        "\n",
        "    Args:\n",
        "        l1_ratio (float): The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.\n",
        "                          l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset (you can replace this with your own)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model with Elastic Net regularization\n",
        "    model = LogisticRegression(\n",
        "        penalty='elasticnet',\n",
        "        solver='saga',  # 'saga' is required for Elastic Net\n",
        "        l1_ratio=l1_ratio,\n",
        "        max_iter=1000\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Elastic Net Logistic Regression Accuracy (l1_ratio={l1_ratio}): {accuracy:.4f}\")\n",
        "\n",
        "    # Print the model coefficients\n",
        "    print(\"\\nModel Coefficients:\")\n",
        "\n",
        "    if len(model.coef_.shape) > 1: #multi-class\n",
        "        for i, coef in enumerate(model.coef_):\n",
        "            print(f\"Class {i}: {coef}\")\n",
        "    else: #binary-class\n",
        "        print(model.coef_)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    elastic_net_logistic_regression_example(l1_ratio=0.5)  # Example with l1_ratio=0.5\n",
        "    elastic_net_logistic_regression_example(l1_ratio=0) #example with l2 regularization\n",
        "    elastic_net_logistic_regression_example(l1_ratio=1) #example with l1 regularization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPE9kFF4BXjX",
        "outputId": "cde7ea08-6c98-4f63-84f9-0b271978d46b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Logistic Regression Accuracy (l1_ratio=0.5): 1.0000\n",
            "\n",
            "Model Coefficients:\n",
            "Class 0: [ 0.02857503  1.59712019 -2.42639143 -0.59308994]\n",
            "Class 1: [ 0.          0.          0.         -0.50456896]\n",
            "Class 2: [-0.78029492 -0.95719616  2.74500417  2.09728411]\n",
            "Elastic Net Logistic Regression Accuracy (l1_ratio=0): 1.0000\n",
            "\n",
            "Model Coefficients:\n",
            "Class 0: [ 0.20716261  1.31438928 -2.28429724 -1.00924445]\n",
            "Class 1: [ 0.30224018 -0.32705459 -0.14238632 -0.74765486]\n",
            "Class 2: [-0.50940279 -0.98733468  2.42668355  1.75689931]\n",
            "Elastic Net Logistic Regression Accuracy (l1_ratio=1): 1.0000\n",
            "\n",
            "Model Coefficients:\n",
            "Class 0: [ 0.          2.09033933 -2.69722549  0.        ]\n",
            "Class 1: [0. 0. 0. 0.]\n",
            "Class 2: [-1.0919559  -1.27855801  3.18060274  3.21770088]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "c_Jn_P6oBlme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example multiclass dataset\n",
        "\n",
        "def ovr_logistic_regression_example():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model for multiclass classification using multi_class='ovr' (One-vs-Rest).\n",
        "    Prints the model's accuracy and coefficients.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a multiclass dataset (Iris dataset)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model with multi_class='ovr'\n",
        "    model = LogisticRegression(multi_class='ovr', max_iter=1000)  # Explicitly set multi_class='ovr'\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"OVR Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Print the model coefficients\n",
        "    print(\"\\nModel Coefficients:\")\n",
        "\n",
        "    if len(model.coef_.shape) > 1: #multi-class\n",
        "        for i, coef in enumerate(model.coef_):\n",
        "            print(f\"Class {i}: {coef}\")\n",
        "    else: #binary-class\n",
        "        print(model.coef_)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ovr_logistic_regression_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzKwotBLBiEx",
        "outputId": "56ace661-90e9-40f6-af4f-be0f04b9ccac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OVR Logistic Regression Accuracy: 0.9667\n",
            "\n",
            "Model Coefficients:\n",
            "Class 0: [-0.42762216  0.88771927 -2.21471658 -0.91610036]\n",
            "Class 1: [-0.03387836 -2.0442989   0.54266011 -1.0179372 ]\n",
            "Class 2: [-0.38904645 -0.62147609  2.7762982   2.09067085]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "JwdgPvipB0X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def logistic_regression_grid_search():\n",
        "    \"\"\"\n",
        "    Applies GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression.\n",
        "    Prints the best parameters and accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset (you can replace this with your own)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "        'penalty': ['l1', 'l2', 'elasticnet', None],\n",
        "        'solver': ['liblinear', 'saga'], # solvers that support l1 and elasticnet\n",
        "        'l1_ratio': [0.25, 0.5, 0.75] # used only for elasticnet\n",
        "    }\n",
        "\n",
        "    # Create the Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # Create the GridSearchCV object\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
        "\n",
        "    # Perform the grid search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Print the best parameters and accuracy\n",
        "    print(\"Best Parameters:\", grid_search.best_params_)\n",
        "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "    # Evaluate on the test set with the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Test Accuracy with Best Model:\", test_accuracy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_grid_search()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4brNFsYByFU",
        "outputId": "b4c84f72-164b-48d4-912c-71c948e04cdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "180 fits failed out of a total of 720.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 76, in _check_solver\n",
            "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
            "ValueError: penalty=None is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.33333333 0.33333333 0.375      0.81666667        nan 0.325\n",
            "        nan 0.95833333 0.33333333 0.325      0.375      0.81666667\n",
            "        nan 0.33333333        nan 0.95833333 0.33333333 0.325\n",
            " 0.375      0.81666667        nan 0.33333333        nan 0.95833333\n",
            " 0.34166667 0.34166667 0.65833333 0.85833333        nan 0.81666667\n",
            "        nan 0.95833333 0.34166667 0.33333333 0.65833333 0.85833333\n",
            "        nan 0.63333333        nan 0.95833333 0.34166667 0.33333333\n",
            " 0.65833333 0.85833333        nan 0.33333333        nan 0.95833333\n",
            " 0.75       0.925      0.84166667 0.93333333        nan 0.94166667\n",
            "        nan 0.95833333 0.75       0.925      0.84166667 0.93333333\n",
            "        nan 0.94166667        nan 0.95833333 0.75       0.925\n",
            " 0.84166667 0.93333333        nan 0.925             nan 0.95833333\n",
            " 0.94166667 0.95833333 0.95       0.96666667        nan 0.95833333\n",
            "        nan 0.95833333 0.94166667 0.95833333 0.95       0.96666667\n",
            "        nan 0.95833333        nan 0.95833333 0.94166667 0.95833333\n",
            " 0.95       0.96666667        nan 0.95833333        nan 0.95833333\n",
            " 0.95833333 0.95833333 0.95833333 0.96666667        nan 0.96666667\n",
            "        nan 0.95833333 0.95833333 0.95833333 0.95833333 0.96666667\n",
            "        nan 0.96666667        nan 0.95833333 0.95833333 0.95833333\n",
            " 0.95833333 0.96666667        nan 0.96666667        nan 0.95833333\n",
            " 0.95833333 0.95833333 0.95833333 0.95833333        nan 0.95833333\n",
            "        nan 0.95833333 0.95833333 0.95833333 0.95833333 0.95833333\n",
            "        nan 0.95833333        nan 0.95833333 0.95833333 0.95833333\n",
            " 0.95833333 0.95833333        nan 0.95833333        nan 0.95833333]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'l1_ratio': 0.25, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Best Accuracy: 0.9666666666666668\n",
            "Test Accuracy with Best Model: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "u8kma3FECDf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def stratified_kfold_logistic_regression():\n",
        "    \"\"\"\n",
        "    Evaluates Logistic Regression using Stratified K-Fold Cross-Validation and prints the average accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset (you can replace this with your own)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Create the Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # Create StratifiedKFold object\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 5 folds\n",
        "\n",
        "    # Lists to store accuracy scores\n",
        "    accuracy_scores = []\n",
        "\n",
        "    # Perform Stratified K-Fold Cross-Validation\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate and store the accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Calculate and print the average accuracy\n",
        "    average_accuracy = np.mean(accuracy_scores)\n",
        "    print(f\"Average Stratified K-Fold Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    stratified_kfold_logistic_regression()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20nit2xJB983",
        "outputId": "f94f5054-2c75-4619-b256-5866e0effb3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Stratified K-Fold Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "TlqzsqhgCWeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def logistic_regression_from_csv(filepath, target_column):\n",
        "    \"\"\"\n",
        "    Loads a dataset from a CSV file, applies Logistic Regression, and evaluates its accuracy.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): The path to the CSV file.\n",
        "        target_column (str): The name of the target column.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Load the dataset from the CSV file\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Separate features (X) and target (y)\n",
        "        y = df[target_column]\n",
        "        X = df.drop(target_column, axis=1)\n",
        "\n",
        "        # Split the dataset into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Create and train the Logistic Regression model\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate and print the accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {filepath}\")\n",
        "    except KeyError:\n",
        "        print(f\"Error: Target column '{target_column}' not found in the CSV file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Example usage (replace 'your_dataset.csv' and 'target' with your actual file and column names):\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_from_csv('your_dataset.csv', 'target') #replace placeholders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db5KWWsiCTMy",
        "outputId": "e0bf2c78-6dec-404a-feb6-5d0e6759b0df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at your_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "gMK8Xzf8ClGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from scipy.stats import uniform, choice\n",
        "\n",
        "def randomized_search_logistic_regression():\n",
        "    \"\"\"\n",
        "    Applies RandomizedSearchCV to tune hyperparameters (C, penalty, solver) in Logistic Regression.\n",
        "    Prints the best parameters and accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a sample dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Define the parameter distributions\n",
        "    param_distributions = {\n",
        "        'C': uniform(0.001, 100),  # Uniform distribution for C\n",
        "        'penalty': choice(['l1', 'l2', 'elasticnet', None]), # discrete choices\n",
        "        'solver': choice(['liblinear', 'saga']), # discrete choices\n",
        "        'l1_ratio': uniform(0,1) #uniform distribution for l1_ratio\n",
        "    }\n",
        "\n",
        "    # Create the Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # Create RandomizedSearchCV object\n",
        "    random_search = RandomizedSearchCV(\n",
        "        model,\n",
        "        param_distributions,\n",
        "        n_iter=100,  # Number of parameter settings sampled\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Perform the randomized search\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Print the best parameters and accuracy\n",
        "    print(\"Best Parameters:\", random_search.best_params_)\n",
        "    print(\"Best Accuracy:\", random_search.best_score_)\n",
        "\n",
        "    # Evaluate on the test set with the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Test Accuracy with Best Model:\", test_accuracy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    randomized_search_logistic_regression()"
      ],
      "metadata": {
        "id": "qLLaj_HCDDje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "Jn5Md-SLDh6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example multiclass dataset\n",
        "from itertools import combinations\n",
        "\n",
        "def ovo_logistic_regression():\n",
        "    \"\"\"\n",
        "    Implements One-vs-One (OvO) Multiclass Logistic Regression and prints the accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load a multiclass dataset (Iris dataset)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    unique_classes = np.unique(y)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create a list to store the OvO classifiers\n",
        "    classifiers = []\n",
        "\n",
        "    # Train OvO classifiers\n",
        "    for class_pair in combinations(unique_classes, 2):\n",
        "        class1, class2 = class_pair\n",
        "        indices = np.logical_or(y_train == class1, y_train == class2)\n",
        "        X_pair = X_train[indices]\n",
        "        y_pair = y_train[indices]\n",
        "        y_pair_binary = np.where(y_pair == class1, 0, 1)  # Binary labels\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_pair, y_pair_binary)\n",
        "        classifiers.append((class_pair, model))\n",
        "\n",
        "    # Make OvO predictions on the test set\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        votes = {}\n",
        "        for (class1, class2), model in classifiers:\n",
        "            y_pred_binary = model.predict(x.reshape(1, -1))[0]\n",
        "            predicted_class = class1 if y_pred_binary == 0 else class2\n",
        "            votes[predicted_class] = votes.get(predicted_class, 0) + 1\n",
        "        predicted_class = max(votes, key=votes.get)  # Majority vote\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"One-vs-One Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ovo_logistic_regression()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMQbw6wkDZeC",
        "outputId": "da97fe09-a864-4679-e7b5-64f65628059b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One Logistic Regression Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "gizu_WALDttt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import make_classification #for binary classification\n",
        "\n",
        "def visualize_binary_logistic_regression_confusion_matrix():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model for binary classification and visualizes the confusion matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Visualize the confusion matrix using seaborn and matplotlib\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Negative', 'Positive'],\n",
        "                yticklabels=['Negative', 'Positive'])\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix for Logistic Regression')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_binary_logistic_regression_confusion_matrix()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "SyD2zR0XDsHq",
        "outputId": "15498bc6-8a4d-4ae7-bc1b-dddc905d1a2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "hy59paY7D60u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification  # Example binary classification dataset\n",
        "\n",
        "def evaluate_logistic_regression_performance():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model and evaluates its performance using Precision, Recall, and F1-Score.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Precision, Recall, and F1-Score\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Print the evaluation metrics\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate_logistic_regression_performance()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMKVflxqD495",
        "outputId": "3876539a-515c-443e-aee1-f9306d03a6f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9000\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "D8lTXtdBEIv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def logistic_regression_imbalanced_data():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model on imbalanced data and applies class weights.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate an imbalanced dataset\n",
        "    X, y = make_classification(n_samples=1000, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, weights=[0.9, 0.1],\n",
        "                               random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train a Logistic Regression model without class weights\n",
        "    model_no_weights = LogisticRegression()\n",
        "    model_no_weights.fit(X_train, y_train)\n",
        "    y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "    print(\"Logistic Regression without Class Weights:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_no_weights))\n",
        "    print(classification_report(y_test, y_pred_no_weights))\n",
        "\n",
        "    # Train a Logistic Regression model with class weights\n",
        "    model_with_weights = LogisticRegression(class_weight='balanced')\n",
        "    model_with_weights.fit(X_train, y_train)\n",
        "    y_pred_with_weights = model_with_weights.predict(X_test)\n",
        "\n",
        "    print(\"\\nLogistic Regression with Class Weights:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_with_weights))\n",
        "    print(classification_report(y_test, y_pred_with_weights))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_imbalanced_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRQ0qt70EHU_",
        "outputId": "5d1c7fe6-514a-48a5-f6d5-372a6fae6580"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression without Class Weights:\n",
            "Accuracy: 0.975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       182\n",
            "           1       0.93      0.78      0.85        18\n",
            "\n",
            "    accuracy                           0.97       200\n",
            "   macro avg       0.96      0.89      0.92       200\n",
            "weighted avg       0.97      0.97      0.97       200\n",
            "\n",
            "\n",
            "Logistic Regression with Class Weights:\n",
            "Accuracy: 0.88\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93       182\n",
            "           1       0.42      0.89      0.57        18\n",
            "\n",
            "    accuracy                           0.88       200\n",
            "   macro avg       0.70      0.88      0.75       200\n",
            "weighted avg       0.94      0.88      0.90       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."
      ],
      "metadata": {
        "id": "mND79jDWEWt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def logistic_regression_titanic():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model on the Titanic dataset, handles missing values,\n",
        "    and evaluates performance.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the Titanic dataset\n",
        "    try:\n",
        "        df = pd.read_csv(\"titanic.csv\") # Ensure 'titanic.csv' is in the same directory\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: titanic.csv not found.\")\n",
        "        return\n",
        "\n",
        "    # Preprocessing:\n",
        "    # 1. Select relevant features and target.\n",
        "    df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "\n",
        "    # 2. Separate features (X) and target (y).\n",
        "    y = df['Survived']\n",
        "    X = df.drop('Survived', axis=1)\n",
        "\n",
        "    # 3. Define numerical and categorical features.\n",
        "    numerical_features = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\n",
        "    categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "    # 4. Create transformers for numerical and categorical features.\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # 5. Combine transformers using ColumnTransformer.\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # 6. Create the full pipeline: preprocessing + Logistic Regression.\n",
        "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                            ('classifier', LogisticRegression(max_iter=1000))])\n",
        "\n",
        "    # Split the dataset into training and testing sets.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train the model.\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set.\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance.\n",
        "    print(\"Logistic Regression on Titanic Dataset:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_titanic()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umq9eHoeEUeR",
        "outputId": "3f65b33e-853e-45c0-8059-8db180c485d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: titanic.csv not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "ysRQP-L1EmY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def logistic_regression_with_scaling():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model with and without feature scaling (Standardization)\n",
        "    and compares their accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the Iris dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Logistic Regression without scaling\n",
        "    model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "    model_no_scaling.fit(X_train, y_train)\n",
        "    y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "    accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "    print(\"Logistic Regression without Scaling:\")\n",
        "    print(f\"Accuracy: {accuracy_no_scaling:.4f}\")\n",
        "\n",
        "    # Logistic Regression with scaling\n",
        "    model_with_scaling = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('logistic', LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "    model_with_scaling.fit(X_train, y_train)\n",
        "    y_pred_with_scaling = model_with_scaling.predict(X_test)\n",
        "    accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "\n",
        "    print(\"\\nLogistic Regression with Scaling:\")\n",
        "    print(f\"Accuracy: {accuracy_with_scaling:.4f}\")\n",
        "\n",
        "    # Compare the results\n",
        "    print(\"\\nComparison:\")\n",
        "    print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "    print(f\"Accuracy with scaling: {accuracy_with_scaling:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_with_scaling()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2khJEyNREgGM",
        "outputId": "ef6e523b-1366-4109-f63b-ee0ad1d9a8b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression without Scaling:\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Logistic Regression with Scaling:\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Comparison:\n",
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "d9mGQ4J9EzwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def logistic_regression_roc_auc():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model and evaluates its performance using ROC-AUC score.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make probability predictions on the test set\n",
        "    y_prob = model.predict_proba(X_test)[:, 1] # probability of class 1\n",
        "\n",
        "    # Calculate ROC-AUC score\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    # Print the ROC-AUC score\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_roc_auc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwYbuNQuEyT2",
        "outputId": "45ca7aef-dbb2-4ee7-f0a1-0cb878d906e8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."
      ],
      "metadata": {
        "id": "Wb4pzdvsFAtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def logistic_regression_custom_learning_rate():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model with a custom learning rate (C=0.5) and evaluates accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model with custom learning rate (C=0.5)\n",
        "    model = LogisticRegression(C=0.5, max_iter=1000) # C is the inverse of regularization strength\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Logistic Regression Accuracy (C=0.5): {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_custom_learning_rate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpQ5nqSdE9EF",
        "outputId": "29e6c951-9af7-4385-c558-4847184a9c21"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy (C=0.5): 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18. Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "sSOmocB9FLqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris  # Example dataset\n",
        "\n",
        "def logistic_regression_feature_importance():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model and identifies important features based on model coefficients.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the Iris dataset (or replace with your dataset)\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    feature_names = iris.feature_names\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Get the model coefficients\n",
        "    coefficients = model.coef_\n",
        "\n",
        "    # Handle multiclass coefficients\n",
        "    if len(coefficients.shape) > 1:  # Multiclass\n",
        "        for i, coef in enumerate(coefficients):\n",
        "            print(f\"\\nClass {i} Feature Importance:\")\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'Feature': feature_names,\n",
        "                'Coefficient': coef\n",
        "            })\n",
        "            feature_importance['Absolute Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
        "            feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
        "            print(feature_importance)\n",
        "\n",
        "    else: #Binary Class\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'Feature': feature_names,\n",
        "            'Coefficient': coefficients[0]\n",
        "        })\n",
        "        feature_importance['Absolute Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
        "        feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
        "        print(\"Feature Importance:\")\n",
        "        print(feature_importance)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_feature_importance()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nX8_hK-FKTt",
        "outputId": "99a216ee-038b-4e59-e081-df13e75c821c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class 0 Feature Importance:\n",
            "             Feature  Coefficient  Absolute Coefficient\n",
            "2  petal length (cm)    -2.375108              2.375108\n",
            "3   petal width (cm)    -0.998746              0.998746\n",
            "1   sepal width (cm)     0.962586              0.962586\n",
            "0  sepal length (cm)    -0.393402              0.393402\n",
            "\n",
            "Class 1 Feature Importance:\n",
            "             Feature  Coefficient  Absolute Coefficient\n",
            "3   petal width (cm)    -0.775755              0.775755\n",
            "0  sepal length (cm)     0.508404              0.508404\n",
            "1   sepal width (cm)    -0.254865              0.254865\n",
            "2  petal length (cm)    -0.213014              0.213014\n",
            "\n",
            "Class 2 Feature Importance:\n",
            "             Feature  Coefficient  Absolute Coefficient\n",
            "2  petal length (cm)     2.588121              2.588121\n",
            "3   petal width (cm)     1.774501              1.774501\n",
            "1   sepal width (cm)    -0.707721              0.707721\n",
            "0  sepal length (cm)    -0.115002              0.115002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score."
      ],
      "metadata": {
        "id": "QFozV51_FV-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def logistic_regression_cohen_kappa():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model and evaluates its performance using Cohen's Kappa Score.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Cohen's Kappa score\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Print the Cohen's Kappa score\n",
        "    print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_cohen_kappa()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a24tR04PFUae",
        "outputId": "97b5b8f4-0314-47e1-8072-3d7265622c22"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "UpBSFTmjFg9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def visualize_precision_recall_curve():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model and visualizes the Precision-Recall Curve for binary classification.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make probability predictions on the test set\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate Precision, Recall, and Thresholds\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "    # Calculate the area under the Precision-Recall curve (AUC-PR)\n",
        "    auc_pr = auc(recall, precision)\n",
        "\n",
        "    # Plot the Precision-Recall Curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, label=f'AUC-PR = {auc_pr:.4f}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc='lower left')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_precision_recall_curve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mRjMIUhBFfxT",
        "outputId": "127b5f9f-da8b-43cd-aa18-f436975d4710"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."
      ],
      "metadata": {
        "id": "Slp1KrHbFxqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def compare_logistic_regression_solvers():\n",
        "    \"\"\"\n",
        "    Trains Logistic Regression with different solvers (liblinear, saga, lbfgs) and compares their accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the Iris dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "    accuracies = {}\n",
        "\n",
        "    for solver in solvers:\n",
        "        try:\n",
        "            model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            accuracies[solver] = accuracy\n",
        "            print(f\"Accuracy with solver '{solver}': {accuracy:.4f}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Solver '{solver}' encountered an error: {e}\")\n",
        "\n",
        "    print(\"\\nAccuracy Comparison:\")\n",
        "    for solver, accuracy in accuracies.items():\n",
        "        print(f\"{solver}: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    compare_logistic_regression_solvers()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6jGnSuzFu_b",
        "outputId": "02f72a37-ac52-451d-eba8-8c6606111d77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver 'liblinear': 1.0000\n",
            "Accuracy with solver 'saga': 1.0000\n",
            "Accuracy with solver 'lbfgs': 1.0000\n",
            "\n",
            "Accuracy Comparison:\n",
            "liblinear: 1.0000\n",
            "saga: 1.0000\n",
            "lbfgs: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "Tcfag5ppF9Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def logistic_regression_mcc():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model and evaluates its performance using Matthews Correlation Coefficient (MCC).\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient (MCC)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    # Print the MCC score\n",
        "    print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_mcc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_azaewQzF7xw",
        "outputId": "b6fac244-c69c-4ea3-d4ea-dc42e42c84b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.9045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "FkEFplFCGK6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def compare_logistic_regression_scaling():\n",
        "    \"\"\"\n",
        "    Trains Logistic Regression on raw and standardized data and compares their accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the Iris dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Logistic Regression on raw data\n",
        "    model_raw = LogisticRegression(max_iter=1000)\n",
        "    model_raw.fit(X_train, y_train)\n",
        "    y_pred_raw = model_raw.predict(X_test)\n",
        "    accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "    print(f\"Accuracy on raw data: {accuracy_raw:.4f}\")\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Logistic Regression on standardized data\n",
        "    model_scaled = LogisticRegression(max_iter=1000)\n",
        "    model_scaled.fit(X_train_scaled, y_train)\n",
        "    y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "    accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "    print(f\"Accuracy on standardized data: {accuracy_scaled:.4f}\")\n",
        "\n",
        "    # Compare the results\n",
        "    print(\"\\nComparison:\")\n",
        "    print(f\"Raw data accuracy: {accuracy_raw:.4f}\")\n",
        "    print(f\"Standardized data accuracy: {accuracy_scaled:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    compare_logistic_regression_scaling()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Jxz0qRGJ47",
        "outputId": "3dc2377e-a0ce-42c2-dd74-78ae3bf7edd4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 1.0000\n",
            "Accuracy on standardized data: 1.0000\n",
            "\n",
            "Comparison:\n",
            "Raw data accuracy: 1.0000\n",
            "Standardized data accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "6ahWPgRoGaFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def find_optimal_c_logistic_regression():\n",
        "    \"\"\"\n",
        "    Trains Logistic Regression and finds the optimal C (regularization strength) using cross-validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the Iris dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Split the dataset into training and testing sets (for final evaluation)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Define the range of C values to try\n",
        "    C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "    best_c = None\n",
        "    best_score = 0\n",
        "\n",
        "    # Find the optimal C using cross-validation\n",
        "    for c in C_values:\n",
        "        model = LogisticRegression(C=c, max_iter=1000)  # max_iter added\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
        "        mean_score = np.mean(scores)\n",
        "\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_c = c\n",
        "\n",
        "    print(f\"Optimal C: {best_c}\")\n",
        "    print(f\"Best Cross-Validation Accuracy: {best_score:.4f}\")\n",
        "\n",
        "    # Train the final model with the optimal C on the entire training set\n",
        "    final_model = LogisticRegression(C=best_c, max_iter=1000)\n",
        "    final_model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the final model on the test set\n",
        "    test_score = final_model.score(X_test, y_test)\n",
        "    print(f\"Test Accuracy with Optimal C: {test_score:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    find_optimal_c_logistic_regression()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX1ipj3HGY9q",
        "outputId": "080a33da-f7f1-4ddf-f1e9-c928a3a43591"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 1\n",
            "Best Cross-Validation Accuracy: 0.9667\n",
            "Test Accuracy with Optimal C: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "utl8w5CCGmNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "import joblib  # For saving and loading models\n",
        "\n",
        "def logistic_regression_save_load():\n",
        "    \"\"\"\n",
        "    Trains a Logistic Regression model, saves it using joblib, and loads it to make predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a sample binary classification dataset\n",
        "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                               n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained model using joblib\n",
        "    joblib.dump(model, 'logistic_regression_model.joblib')\n",
        "    print(\"Model saved as logistic_regression_model.joblib\")\n",
        "\n",
        "    # Load the saved model\n",
        "    loaded_model = joblib.load('logistic_regression_model.joblib')\n",
        "    print(\"Model loaded successfully.\")\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "    # Calculate and print the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with loaded model: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logistic_regression_save_load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtI_DrsDGlEP",
        "outputId": "a5496793-1ce1-46ed-9702-ef8c931d971e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as logistic_regression_model.joblib\n",
            "Model loaded successfully.\n",
            "Accuracy with loaded model: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-iYB2MhvGyDh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}